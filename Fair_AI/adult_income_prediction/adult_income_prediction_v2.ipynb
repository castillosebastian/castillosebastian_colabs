{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/castillosebastian/castillosebastian_colabs/blob/main/adult_income_prediction/adult_income_prediction.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair IA: An Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are goint to test 'fair-ml' algorithms. We are going to work with *Adult* dataset (Dua & Graff, 2017) used to predict whether income exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset Train dataset contains 13 features and 30178 observations. Test dataset contains 13 features and 15315 observations. Target column is \"target\": A binary factor where 1: <=50K and 2: >50K for annual income. The column \"sex\" is set as protected attribute."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebacastillo/.castillosebastian_colabs/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sebacastillo/.castillosebastian_colabs/lib/python3.9/site-packages/torch/_functorch/deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from inFairness.fairalgo import SenSeI\n",
    "from inFairness import distances\n",
    "from inFairness.auditor import SenSRAuditor, SenSeIAuditor\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "names = [\n",
    "        'age', 'workclass', 'fnlwgt', 'education', \n",
    "        'education-num', 'marital-status', 'occupation',\n",
    "        'relationship', 'race', 'sex', 'capital-gain', \n",
    "        'capital-loss', 'hours-per-week', 'native-country',\n",
    "        'annual-income'\n",
    "    ]\n",
    "data = pd.read_csv(url, sep=',', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>annual-income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country annual-income  \n",
       "0          2174             0              40   United-States         <=50K  \n",
       "1             0             0              13   United-States         <=50K  \n",
       "2             0             0              40   United-States         <=50K  \n",
       "3             0             0              40   United-States         <=50K  \n",
       "4             0             0              40            Cuba         <=50K  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annual-income\n",
       " <=50K    24720\n",
       " >50K      7841\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annual-income'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is imbalanced: 25% make at least $50k per year. This imbalanced also appears in *sex* and *race* as shown here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annual-income</th>\n",
       "      <th>sex</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>15128</td>\n",
       "      <td>46.460490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Female</td>\n",
       "      <td>9592</td>\n",
       "      <td>29.458555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>6662</td>\n",
       "      <td>20.460060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Female</td>\n",
       "      <td>1179</td>\n",
       "      <td>3.620896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annual-income      sex  count  percentage\n",
       "0         <=50K     Male  15128   46.460490\n",
       "1         <=50K   Female   9592   29.458555\n",
       "2          >50K     Male   6662   20.460060\n",
       "3          >50K   Female   1179    3.620896"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(imbal_sex := data.groupby(['annual-income', 'sex']).size() \n",
    "   .sort_values(ascending=False) \n",
    "   .reset_index(name='count')\n",
    "   .assign(percentage = lambda df:100 * df['count']/df['count'].sum())   \n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annual-income</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>White</td>\n",
       "      <td>20699</td>\n",
       "      <td>63.569915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>White</td>\n",
       "      <td>7117</td>\n",
       "      <td>21.857437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Black</td>\n",
       "      <td>2737</td>\n",
       "      <td>8.405761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>763</td>\n",
       "      <td>2.343294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Black</td>\n",
       "      <td>387</td>\n",
       "      <td>1.188538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>276</td>\n",
       "      <td>0.847640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>275</td>\n",
       "      <td>0.844569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Other</td>\n",
       "      <td>246</td>\n",
       "      <td>0.755505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>36</td>\n",
       "      <td>0.110562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Other</td>\n",
       "      <td>25</td>\n",
       "      <td>0.076779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annual-income                 race  count  percentage\n",
       "0         <=50K                White  20699   63.569915\n",
       "1          >50K                White   7117   21.857437\n",
       "2         <=50K                Black   2737    8.405761\n",
       "3         <=50K   Asian-Pac-Islander    763    2.343294\n",
       "4          >50K                Black    387    1.188538\n",
       "5          >50K   Asian-Pac-Islander    276    0.847640\n",
       "6         <=50K   Amer-Indian-Eskimo    275    0.844569\n",
       "7         <=50K                Other    246    0.755505\n",
       "8          >50K   Amer-Indian-Eskimo     36    0.110562\n",
       "9          >50K                Other     25    0.076779"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(imbal_race := data.groupby(['annual-income', 'race']).size() \n",
    "   .sort_values(ascending=False) \n",
    "   .reset_index(name='count')\n",
    "   .assign(percentage = lambda df:100 * df['count']/df['count'].sum())   \n",
    "   )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Nural Network model folowing IBM Research\n",
    "\n",
    "Source [inFairness](https://github.com/IBM/inFairness/blob/main/examples/adult-income-prediction/adult_income_prediction.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdultDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the categorical variable are transformed into one-hot variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "train_df, test_df = data.load_data()\n",
    "X_train_df, Y_train_df = train_df\n",
    "X_test_df, Y_test_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>education-num</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>marital-status_Divorced</th>\n",
       "      <th>marital-status_Married-AF-spouse</th>\n",
       "      <th>marital-status_Married-civ-spouse</th>\n",
       "      <th>marital-status_Married-spouse-absent</th>\n",
       "      <th>marital-status_Never-married</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_Unmarried</th>\n",
       "      <th>relationship_Wife</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>workclass_State-gov</th>\n",
       "      <th>workclass_Without-pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.409331</td>\n",
       "      <td>-0.14652</td>\n",
       "      <td>-0.218253</td>\n",
       "      <td>-1.613806</td>\n",
       "      <td>-0.49677</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  capital-gain  capital-loss  education-num  hours-per-week  \\\n",
       "0  0.409331      -0.14652     -0.218253      -1.613806        -0.49677   \n",
       "\n",
       "   marital-status_Divorced  marital-status_Married-AF-spouse  \\\n",
       "0                    False                             False   \n",
       "\n",
       "   marital-status_Married-civ-spouse  marital-status_Married-spouse-absent  \\\n",
       "0                              False                                 False   \n",
       "\n",
       "   marital-status_Never-married  ...  relationship_Unmarried  \\\n",
       "0                          True  ...                    True   \n",
       "\n",
       "   relationship_Wife  sex_Male  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "0              False     False                  False                False   \n",
       "\n",
       "   workclass_Private  workclass_Self-emp-inc  workclass_Self-emp-not-inc  \\\n",
       "0               True                   False                       False   \n",
       "\n",
       "   workclass_State-gov  workclass_Without-pay  \n",
       "0                False                  False  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the IBM-inFairness model [example](https://github.com/IBM/inFairness/blob/main/examples/adult-income-prediction/adult_income_prediction.ipynb) the protected attributes are droped from the training and test data. That is usually de case in fairness-aware machine learning when we deal with features that we know area biased. The idea is to prevent the model from directly learning to make decisions based on these sensitive attributes, which could lead to discriminatory outcomes.\n",
    "\n",
    "However, this approach has some limitations. Even if you remove the protected attribute, other features in the dataset might act as proxies for it: meaning they may retaing a strong signal of the bias information. As an example certain occupations, neighborhoods, or education levels might be disproportionately associated with certain racial groups due to societal factors. So, even without explicit information about race, the model might still end up learning patterns that indirectly reflect racial biases.\n",
    "\n",
    "On the odther hand, removing sensitives attributes makes it difficult to analyze the fairness of the model. If we don't know the race of the individuals in our dataset, we can't check whether our model is treating individuals of different races equally.\n",
    "\n",
    "In some cases, it's important to consider sensitive attributes to ensure fairness. For example, in order to correct for historical biases or to achieve certain diversity and inclusion goals, it might be necessary to consider these attributes.\n",
    "\n",
    "So, while removing sensitive attributes might seem like an easy fix, it doesn't necessarily solve the problem of bias and might introduce new problems. Instead, it's often better to use techniques that aim to ensure that the model treats similar individuals similarly (individual fairness), regardless of their sensitive attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_vars = ['race_White', 'sex_Male']\n",
    "X_protected_df = X_train_df[protected_vars]\n",
    "X_train_df = X_train_df.drop(columns=protected_vars)\n",
    "X_test_df = X_test_df.drop(columns=protected_vars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of assessing individual fairness, the example we are working with implements a variable consistency measure using the 'spouse' attribute. This involves flipping the 'spouse' variable in the dataset, essentially simulating a scenario where individuals with the same characteristics but different 'spouse' values are compared. The goal is to ensure that the model's predictions are consistent for individuals who are similar except for their 'spouse' attribute, thereby upholding the principle of individual fairness. This approach provides a practical way to audit the model's fairness by checking if similar individuals are treated similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.relationship_Wife.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test_df_spouse_flipped = X_test_df.copy()\n",
    "X_test_df_spouse_flipped.relationship_Wife = 1 - X_test_df_spouse_flipped.relationship_Wife\n",
    "X_test_df_spouse_flipped.relationship_Wife.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# Convert all pandas dataframes to PyTorch tensors\n",
    "X_train, y_train = data.convert_df_to_tensor(X_train_df, Y_train_df)\n",
    "X_test, y_test = data.convert_df_to_tensor(X_test_df, Y_test_df)\n",
    "X_test_flip, y_test_flip = data.convert_df_to_tensor(X_test_df_spouse_flipped, Y_test_df)\n",
    "X_protected = torch.tensor(X_protected_df.values).float()\n",
    "\n",
    "# Create the training and testing dataset\n",
    "train_ds = AdultDataset(X_train, y_train)\n",
    "test_ds = AdultDataset(X_test, y_test)\n",
    "test_ds_flip = AdultDataset(X_test_flip, y_test_flip)\n",
    "\n",
    "# Create train and test dataloaders\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=1000, shuffle=False)\n",
    "test_dl_flip = DataLoader(test_ds_flip, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test a Multilayer neural network as proposed in the IBM implementation example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fcout = nn.Linear(100, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fcout(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "output_size = 2\n",
    "\n",
    "network_standard = Model(input_size, output_size).to(device)\n",
    "optimizer = torch.optim.Adam(network_standard.parameters(), lr=1e-3)\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "network_standard.train()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "    for x, y in train_dl:\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = network_standard(x).squeeze()\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8555948734283447\n",
      "Balanced accuracy: 0.7764129391420478\n",
      "Spouse consistency: 0.9636222910216719\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy(network_standard, test_dl, device)\n",
    "balanced_acc = metrics.balanced_accuracy(network_standard, test_dl, device)\n",
    "spouse_consistency = metrics.spouse_consistency(network_standard, test_dl, test_dl_flip, device)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Balanced accuracy: {balanced_acc}')\n",
    "print(f'Spouse consistency: {spouse_consistency}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple NN achieve .85 of accuracy. However, the inconsistency score of 0.04 on the 'spouse' variable suggests that the model is not treating similar individuals consistently, which is a violation of individual fairness. This inconsistency could be due to the model learning to differentiate based on gender, despite the intention to avoid such bias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individually fair training with LogReg fair metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, a fair machine learning model is introduced. This model is said to be fair because its performance remains consistent under certain perturbations within a sensitive subspace, meaning it is robust to partial data variations.\n",
    "\n",
    "To illustrate the authors' approach, let us consider the process of evaluating the fairness of a resume screening system. An auditor might alter the names on resumes of Caucasian applicants to those more commonly found among the African-American population. If the system's performance declines upon reviewing the altered resumes (i.e., the evaluations become less favorable), one could infer that the model exhibits bias against African-American applicants.\n",
    "\n",
    "To algorithmically address this issue, the authors propose a method to instill individual fairness during the training of ML models. This is achieved through *distributionally robust optimization* (DRO), an optimization technique that seeks the optimal solution while considering a fairness metric (inspired by Adversarial Robustness). The implementation is designed to ensure that the ML model maintains fairness not only with the training and testing data but also with new data from the same distribution.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning fair metric from data and its hidden signals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors use Wasserstein distances to measure the similarity between individuals. Unlike Mahalanobis, Wasserstein distance can be used to compare two probability distributions and is defined as the minimum cost that must be paid to transform one distribution into the other.  The distances between data points are calculated in a way that takes into account protected attributes (in our example: gender or race). The goal is to ensure that similar individuals, as determined by Wasserstein distance, are treated similarly by the machine learning model.\n",
    "\n",
    "To achieve this, the algorithm learn 'sensitive directions' in the data. These are directions in the feature space along which changes are likely to correspond to changes in protected attributes. These is a clever approach to uncover hidden biases by identifying subtle patterns that may correspond to changes in protected attributes, even if those attributes are not present in our model inputs. This allows the model to account for potential biases that might otherwise go unnoticed. \n",
    "\n",
    "For instance, to identify a sensitive direction associated with a particular attribute (e.g., gender), the algorithm use a logistic regression classifier to distinguish between classes (such as men and women in the data). The coefficients from this logistic regression model define a direction within the feature space. The algorithm then disregards these 'sensitive directions' while calculating the fair metric. This ensures that differences along sensitive directions are not factored into the distance computation between two individuals. The purpose of this approach is to prevent the machine learning model from discriminating based on protected attributes.\n",
    "\n",
    "So, by fitting the logistic regression model, the algorithm also learns which features are good predictors of the protected attribute (in this case, gender). This allows it to identify and avoid using features that could lead to unfair discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same architecture we found\n",
    "network_fair_LR = Model(input_size, output_size).to(device)\n",
    "optimizer = torch.optim.Adam(network_fair_LR.parameters(), lr=1e-3)\n",
    "lossfn = F.cross_entropy\n",
    "\n",
    "# set the distance metric for instances similiraty detections\n",
    "distance_x_LR = distances.LogisticRegSensitiveSubspace()\n",
    "distance_y = distances.SquaredEuclideanDistance()\n",
    "\n",
    "# train fair metric\n",
    "distance_x_LR.fit(X_train, data_SensitiveAttrs=X_protected)\n",
    "distance_y.fit(num_dims=output_size)\n",
    "\n",
    "distance_x_LR.to(device)\n",
    "distance_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 5.0\n",
    "eps = 0.1\n",
    "auditor_nsteps = 100\n",
    "auditor_lr = 1e-3\n",
    "\n",
    "fairalgo_LR = SenSeI(network_fair_LR, distance_x_LR, distance_y, lossfn, rho, eps, auditor_nsteps, auditor_lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A fair objective function\n",
    "\n",
    "The objective function that is minimized during the training of a fair machine learning model as proposed in the inFairness package is composed of two parts: the loss function and the fair metric (see [SenSeI](https://ibm.github.io/inFairness/_modules/inFairness/fairalgo/sensei.html#SenSeI)): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_loss = torch.mean(\n",
    "            #--------1------------- + -----------------2-----------------------------# \n",
    "            self.loss_fn(Y_pred, Y) + self.rho * self.distance_y(Y_pred, Y_pred_worst)\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loss Function: a classical loss function that measure of how well the model's predictions match the actual data. The goal of this metric is to adjust the model's parameters to minimize the loss score, and\n",
    "2. Fair Metric (DIF): the fairness term is a measure of the difference between the model's predictions on the original data and its predictions on the worst-case examples. \n",
    "\n",
    "The model is trying to minimize this objective function, which means it's trying to make accurate and fair predictions.\n",
    "\n",
    "It's important to note that due to the computation of a complex loss score, the training process becomes more resource-intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:09<00:00, 60.90s/it]\n"
     ]
    }
   ],
   "source": [
    "fairalgo_LR.train()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        result = fairalgo_LR(x, y)\n",
    "        result.loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8401150107383728\n",
      "Balanced accuracy: 0.742399333699871\n",
      "Spouse consistency: 0.9997788589119858\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy(network_fair_LR, test_dl, device)\n",
    "balanced_acc = metrics.balanced_accuracy(network_fair_LR, test_dl, device)\n",
    "spouse_consistency = metrics.spouse_consistency(network_fair_LR, test_dl, test_dl_flip, device)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Balanced accuracy: {balanced_acc}')\n",
    "print(f'Spouse consistency: {spouse_consistency}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now audit the models and check for their individual fairness compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebacastillo/.castillosebastian_colabs/lib/python3.9/site-packages/inFairness/auditor/auditor.py:54: RuntimeWarning: invalid value encountered in divide\n",
      "  loss_ratio = np.divide(loss_vals_adversarial, loss_vals_original)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "LR metric\n",
      "Loss ratio (Standard model) : 2.1810670575586046. Is model fair: False\n",
      "Loss ratio (fair model - LogReg metric) : 1.0531351204682995. Is model fair: True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\t As signified by these numbers, the fair models are fairer than the standard model\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Auditing using the SenSR Auditor + LR metric\n",
    "\n",
    "audit_nsteps = 1000\n",
    "audit_lr = 0.1\n",
    "\n",
    "auditor_LR = SenSRAuditor(loss_fn=loss_fn, distance_x=distance_x_LR, num_steps=audit_nsteps, lr=audit_lr, max_noise=0.5, min_noise=-0.5)\n",
    "\n",
    "audit_result_stdmodel = auditor_LR.audit(network_standard, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
    "audit_result_fairmodel_LR = auditor_LR.audit(network_fair_LR, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
    "print(\"=\"*100)\n",
    "print(\"LR metric\")\n",
    "print(f\"Loss ratio (Standard model) : {audit_result_stdmodel.lower_bound}. Is model fair: {audit_result_stdmodel.is_model_fair}\")\n",
    "print(f\"Loss ratio (fair model - LogReg metric) : {audit_result_fairmodel_LR.lower_bound}. Is model fair: {audit_result_fairmodel_LR.is_model_fair}\")\n",
    "print(\"-\"*100)\n",
    "print(\"\\t As signified by these numbers, the fair models are fairer than the standard model\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further explorations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individually fair training with EXPLORE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebacastillo/.castillosebastian_colabs/lib/python3.9/site-packages/inFairness/distances/explore_distance.py:76: RuntimeWarning: overflow encountered in exp\n",
      "  sclVec = 2.0 / (np.exp(diag) - 1)\n"
     ]
    }
   ],
   "source": [
    "Y_gender = X_protected[:, -1]\n",
    "X1, X2, Y_pairs = data.create_data_pairs(X_train, y_train, Y_gender)\n",
    "\n",
    "distance_x_explore = distances.EXPLOREDistance()\n",
    "distance_x_explore.fit(X1, X2, Y_pairs, iters=1000, batchsize=10000)\n",
    "distance_x_explore.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_fair_explore = Model(input_size, output_size).to(device)\n",
    "optimizer = torch.optim.Adam(network_fair_explore.parameters(), lr=1e-3)\n",
    "lossfn = F.cross_entropy\n",
    "\n",
    "rho = 25.0\n",
    "eps = 0.1\n",
    "auditor_nsteps = 10\n",
    "auditor_lr = 1e-2\n",
    "\n",
    "fairalgo_explore = SenSeI(network_fair_explore, distance_x_explore, distance_y, lossfn, rho, eps, auditor_nsteps, auditor_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:17<00:00,  7.71s/it]\n"
     ]
    }
   ],
   "source": [
    "fairalgo_explore.train()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        result = fairalgo_explore(x, y)\n",
    "        result.loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8225342631340027\n",
      "Balanced accuracy: 0.7034968962244807\n",
      "Spouse consistency: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy(network_fair_explore, test_dl, device)\n",
    "balanced_acc = metrics.balanced_accuracy(network_fair_explore, test_dl, device)\n",
    "spouse_consistency = metrics.spouse_consistency(network_fair_explore, test_dl, test_dl_flip, device)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Balanced accuracy: {balanced_acc}')\n",
    "print(f'Spouse consistency: {spouse_consistency}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now audit the three models and check for their individual fairness compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebacastillo/.castillosebastian_colabs/lib/python3.9/site-packages/inFairness/auditor/auditor.py:54: RuntimeWarning: invalid value encountered in divide\n",
      "  loss_ratio = np.divide(loss_vals_adversarial, loss_vals_original)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "LR metric\n",
      "Loss ratio (Standard model) : 2.660843321695338. Is model fair: False\n",
      "Loss ratio (fair model - LogReg metric) : 1.0569381426130153. Is model fair: True\n",
      "Loss ratio (fair model - EXPLORE metric) : 1.027237853086672. Is model fair: True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\t As signified by these numbers, the fair models are fairer than the standard model\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Auditing using the SenSR Auditor + LR metric\n",
    "\n",
    "audit_nsteps = 1000\n",
    "audit_lr = 0.1\n",
    "\n",
    "auditor_LR = SenSRAuditor(loss_fn=loss_fn, distance_x=distance_x_LR, num_steps=audit_nsteps, lr=audit_lr, max_noise=0.5, min_noise=-0.5)\n",
    "\n",
    "audit_result_stdmodel = auditor_LR.audit(network_standard, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
    "audit_result_fairmodel_LR = auditor_LR.audit(network_fair_LR, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
    "audit_result_fairmodel_explore = auditor_LR.audit(network_fair_explore, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"LR metric\")\n",
    "print(f\"Loss ratio (Standard model) : {audit_result_stdmodel.lower_bound}. Is model fair: {audit_result_stdmodel.is_model_fair}\")\n",
    "print(f\"Loss ratio (fair model - LogReg metric) : {audit_result_fairmodel_LR.lower_bound}. Is model fair: {audit_result_fairmodel_LR.is_model_fair}\")\n",
    "print(f\"Loss ratio (fair model - EXPLORE metric) : {audit_result_fairmodel_explore.lower_bound}. Is model fair: {audit_result_fairmodel_explore.is_model_fair}\")\n",
    "print(\"-\"*100)\n",
    "print(\"\\t As signified by these numbers, the fair models are fairer than the standard model\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "EXPLORE metric\n",
      "Loss ratio (Standard model) : 4.319292031489292. Is model fair: False\n",
      "Loss ratio (fair model - LogReg metric) : 1.13404923721215. Is model fair: True\n",
      "Loss ratio (fair model - EXPLORE metric) : 1.0724120239938144. Is model fair: True\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\t As signified by these numbers, the fair models are fairer than the standard model\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Auditing using the SenSR Auditor + EXPLORE metric\n",
    "\n",
    "audit_nsteps = 1000\n",
    "audit_lr = 0.1\n",
    "\n",
    "auditor_explore = SenSRAuditor(loss_fn=loss_fn, distance_x=distance_x_explore, num_steps=audit_nsteps, lr=audit_lr, max_noise=0.5, min_noise=-0.5)\n",
    "\n",
    "audit_result_stdmodel = auditor_explore.audit(network_standard, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
    "audit_result_fairmodel_LR = auditor_explore.audit(network_fair_LR, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
    "audit_result_fairmodel_explore = auditor_explore.audit(network_fair_explore, X_test, y_test, lambda_param=10.0, audit_threshold=1.15)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"EXPLORE metric\")\n",
    "print(f\"Loss ratio (Standard model) : {audit_result_stdmodel.lower_bound}. Is model fair: {audit_result_stdmodel.is_model_fair}\")\n",
    "print(f\"Loss ratio (fair model - LogReg metric) : {audit_result_fairmodel_LR.lower_bound}. Is model fair: {audit_result_fairmodel_LR.is_model_fair}\")\n",
    "print(f\"Loss ratio (fair model - EXPLORE metric) : {audit_result_fairmodel_explore.lower_bound}. Is model fair: {audit_result_fairmodel_explore.is_model_fair}\")\n",
    "print(\"-\"*100)\n",
    "print(\"\\t As signified by these numbers, the fair models are fairer than the standard model\")\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('infairness')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2fcd21fd76dae422ddd233e5f13f95d1b9f33f06ee3b038abc60116b464585a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
