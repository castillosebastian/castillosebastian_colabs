{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The General Discusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pervasive application of machine learning in various industries, coupled with its significant societal impact, has heightened concerns about the fairness and ethical underpinnings of these technologies. More importantly, experiments that unveil biases and disparities inherent in these implementations have dismantled the idea of algorithmic 'neutrality', emphasizes the critical need for alignment with laws and values pertaining to human dignity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ethical concepts involved in this discussion:\n",
    "\n",
    "- fairness,\n",
    "- transparency,\n",
    "- accauntability,\n",
    "- trust"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this setting, the concept of **responsible AI** has arisen as a vital component of every AI project. A key goal in this regard is to develop tools that can facilitate the creation of fair and ethically grounded innovations. In the subsequent sections, we will explore some of these tools, assessing their strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apendix: Laws\n",
    "\n",
    "- **Europa** \n",
    "\n",
    "One of the most important legal documents related to AI Fairness in Europe is the **AI Act**. This act is a step closer to the first rules on Artificial Intelligence and once approved, they will be the world’s first rules on Artificial Intelligence [link](https://www.europarl.europa.eu/news/en/press-room/20230505IPR84904/ai-act-a-step-closer-to-the-first-rules-on-artificial-intelligence). The AI Act aims to ensure a human-centric and ethical development of Artificial Intelligence (AI) in Europe by endorsing new transparency and risk-management rules for AI systems [link](https://www.weforum.org/agenda/2023/03/the-european-union-s-ai-act-explained/)\n",
    "\n",
    "The AI Act is a proposed legal framework by the European Union that aims to significantly bolster regulations on the development and use of artificial intelligence [link](https://www.caidp.org/resources/eu-ai-act/). The proposed legislation focuses primarily on strengthening rules around data quality, transparency, human oversight and accountability. It also aims to address ethical questions and implementation challenges in various sectors ranging from healthcare and education to finance and energy.\n",
    "\n",
    "The cornerstone of the AI Act is a classification system that determines the level of risk an AI technology could pose to the health and safety or fundamental rights of a person. The framework includes four risk tiers: unacceptable, high, limited and minimal. AI systems with limited and minimal risk—like spam filters or video games—are allowed to be used with little requirements other than transparency obligations. Systems deemed to pose an unacceptable risk—like government social scoring and real-time biometric identification systems in public spaces—are prohibited with little exception.\n",
    "\n",
    "High-risk AI systems are permitted, but developers and users must adhere to regulations that require rigorous testing, proper documentation of data quality and an accountability framework that details human oversight. AI deemed high risk include autonomous vehicles, medical devices and critical infrastructure machinery, to name a few.\n",
    "\n",
    "\n",
    "- **United States** \n",
    "\n",
    "The United States does not have a specific AI Fairness Act equivalent to the European Union's AI Act. However, there are several initiatives and laws that aim to ensure fairness and equity in the use of AI. One such initiative is the **Blueprint for an AI Bill of Rights** by the White House Office of Science and Technology Policy. This blueprint is a guide for a society that protects all people from threats posed by AI and uses technologies in ways that reinforce our highest values [link](https://www.whitehouse.gov/ostp/ai-bill-of-rights/).\n",
    "\n",
    "In addition, the Federal Trade Commission (FTC) has decades of experience enforcing three laws important to developers and users of AI: Section 5 of the FTC Act, the Fair Credit Reporting Act, and the Equal Credit Opportunity Act. These laws prohibit unfair or deceptive practices, including the sale or use of racially biased algorithms [link](https://www.ftc.gov/business-guidance/blog/2021/04/aiming-truth-fairness-equity-your-companys-use-ai)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".castillosebastian_colabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
